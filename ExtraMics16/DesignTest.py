import numpy as np
from Signal import *
from scipy.io.wavfile import write,read
from SignalGen import SignalGen
from Preprocessor import Preprocessor
import soundfile as sf
sampledelay=np.array([[0,0],[0,4],[0,10],[0,12],[0,14],[0,18],[3,0],[9,0],[15,0],[21,0],[24,0],[24,4],[24,10],[24,12],[24,14],[24,18]]) 
sig=Sine(1500,0.5,48000)
pe=Preprocessor(interpolate=3)
target_samplerate=48000
sig_gen=SignalGen(16,sampledelay*343/48000)
speech,samplerate=sf.read(("C:/Users/arg/Documents/Datasets/dev-clean.tar/dev-clean/LibriSpeech/dev-clean/2035/147961/2035-147961-0018.flac"))
interpolator=Preprocessor(mirrored=False,interpolate=int(np.ceil(target_samplerate/16000)))
speech=np.reshape(speech,(-1,1))
speech=interpolator.process(speech)
sig_gen.update_delays(0)
angled_speech=sig_gen.delay_and_gain(speech)*0.00
speech1,samplerate=sf.read(("C:/Users/arg/Documents/Datasets/dev-clean.tar/dev-clean/LibriSpeech/dev-clean/652/130737/652-130737-0005.flac"))
interpolator=Preprocessor(mirrored=False,interpolate=int(np.ceil(target_samplerate/16000)))
speech1=np.reshape(speech1,(-1,1))
speech1=interpolator.process(speech1)
sig_gen.update_delays(90)
angled_speech=angled_speech[0:min(len(speech),len(speech1))]+sig_gen.delay_and_gain(speech1)[0:min(len(speech),len(speech1))]
speech2,samplerate=sf.read(("C:/Users/arg/Documents/Datasets/dev-clean.tar/dev-clean/LibriSpeech/dev-clean/6319/64726/6319-64726-0016.flac"))
interpolator=Preprocessor(mirrored=False,interpolate=int(np.ceil(target_samplerate/16000)))
speech2=np.reshape(speech2,(-1,1))
speech2=interpolator.process(speech2)
sig_gen.update_delays(0)
angled_speech=angled_speech[0:min(len(speech),min(len(speech1),len(speech2)))]+sig_gen.delay_and_gain(speech2)[0:min(len(speech),min(len(speech1),len(speech2)))]
# angled_speech+=0.05*np.random.randn(*angled_speech.shape)
# samplesdelayed=np.zeros((16,48000*5))
# for i in range(16):
    
#     samplesdelayed[i]=np.roll(wave,int(sampledelay[i][0]))
noise = np.random.normal(0,1,angled_speech.shape)*0.1
# samplesdelayed+=noise
samplesdelayed=angled_speech.T

# print(samplesdelayed.dtype)
write("ExtraMics16/AudioTests/d1b.wav", 48000,samplesdelayed.T)
samplesmerged=np.zeros((16,198480))
for i in range(16):
    
    samplesmerged[0]+=np.roll(samplesdelayed[i],-int(sampledelay[i][0]))# front
    samplesmerged[1]+=np.roll(samplesdelayed[i],int(sampledelay[i][0]))#back
    samplesmerged[2]+=np.roll(samplesdelayed[i],-int(sampledelay[i][1]))# Left (maybe)
    samplesmerged[3]+=np.roll(samplesdelayed[i],int(sampledelay[i][1]))#Right(maybe)
samplesmerged/=4 
samplesmerged[4]+=np.roll(samplesdelayed[1],int(-5))+ samplesdelayed[6]+   np.roll(samplesdelayed[3],int(-15)) +samplesdelayed[7]
samplesmerged[5]+=np.roll(samplesdelayed[1],int(5))+ samplesdelayed[6]+   np.roll(samplesdelayed[3],int(15)) +samplesdelayed[7]
samplesmerged[6]+=np.roll(samplesdelayed[11],int(-5))+ samplesdelayed[9]+   np.roll(samplesdelayed[13],int(-15)) +samplesdelayed[8]
samplesmerged[7]+=np.roll(samplesdelayed[11],int(5))+ samplesdelayed[9]+   np.roll(samplesdelayed[13],int(15)) +samplesdelayed[8]
samplesmerged[8]+=np.roll(samplesdelayed[5],int(-30))+ samplesdelayed[10]+   np.roll(samplesdelayed[4],int(-25)) +samplesdelayed[9]
samplesmerged[9]+=np.roll(samplesdelayed[5],int(30))+ samplesdelayed[10]+   np.roll(samplesdelayed[4],int(25)) +samplesdelayed[9]
samplesmerged[10]+=np.roll(samplesdelayed[15],int(-30))+ samplesdelayed[0]+   np.roll(samplesdelayed[14],int(-25)) +samplesdelayed[6]
samplesmerged[11]+=np.roll(samplesdelayed[15],int(30))+ samplesdelayed[0]+   np.roll(samplesdelayed[14],int(25)) +samplesdelayed[6]
samplesmerged[12]+=np.roll(samplesdelayed[2],int(-26))+ samplesdelayed[10]+   np.roll(samplesdelayed[4],int(-26)) +samplesdelayed[11]
samplesmerged[13]+=np.roll(samplesdelayed[2],int(26))+ samplesdelayed[10]+   np.roll(samplesdelayed[4],int(26)) +samplesdelayed[11]
samplesmerged[14]+=np.roll(samplesdelayed[14],int(-26))+ samplesdelayed[2]+   np.roll(samplesdelayed[12],int(-26)) +samplesdelayed[0]
samplesmerged[15]+=np.roll(samplesdelayed[14],int(26))+ samplesdelayed[2]+   np.roll(samplesdelayed[12],int(26)) +samplesdelayed[0]

# Now the speical ones  
# 53 degres: 1 6 3 7  dist 15 5
# other 53 : 9 11 8 13 dist 15 5
# mid degrere 5 10   4 9 dist 25.2 30
# other mid : 15 0 14 6 dist 25.2 30
# edge degrre: 2 10 4 11 dist 26 26
# other edge: 14 2 12 0  dist 26 26
samplesmerged/=4

write("ExtraMics16/AudioTests/d1p.wav", 48000,samplesmerged.T)
samplesmerged/=16
from sklearn.decomposition import FastICA
ica = FastICA(n_components=2, random_state=0)
separated_sources = ica.fit_transform(samplesmerged.T).T
for i, source in enumerate(separated_sources):
    sf.write(f'ExtraMics16/AudioTests/separated_source_{i+1}.wav', source, 48000)  # Assuming a sampling rate of 44100 Hz
for i, source in enumerate(separated_sources):
    plt.figure()
    plt.plot(source)
    plt.title(f'Separated Source {i+1}')
    plt.xlabel('Time')
    plt.ylabel('Amplitude')
    plt.show()
    
# import numpy as np
# import matplotlib.pyplot as plt
# import scipy.fftpack

# Number of samplepoints
# N =int(198480)
# # sample spacing
# T = 1.0 / 48000.0
# x = np.linspace(0.0, N*T, N)
# y = samplesmerged[3]
# yf = scipy.fftpack.fft(y)
# xf = np.linspace(0.0, 1.0/(2.0*T), N//2)

# fig, ax = plt.subplots()
# ax.plot(xf[0:4000], (2.0/N * np.abs(yf[:N//2]))[0:4000])
# plt.show()
# N =int( 198480)
# # sample spacing
# T = 1.0 / 48000.0
# x = np.linspace(0.0, N*T, N)
# y = samplesmerged[ 1]
# yf = scipy.fftpack.fft(y)
# xf = np.linspace(0.0, 1.0/(2.0*T), N//2)

# fig, ax = plt.subplots()
# ax.plot(xf[0:4000], (2.0/N * np.abs(yf[:N//2]))[0:4000])
# plt.show()
# Next steps
# Next goal: Waht i need is some way to take in the 16 directions and split them voices in real time
# 